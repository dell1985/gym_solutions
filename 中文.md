# 强化学问答（Deep）学习教程

本仓库包含使用Gymnasium库（原OpenAI Gym）的强化学习环境进行训练/求解的Python代码。每个解决方案均附有YouTube频道 [@johnnycode](https://www.youtube.com/@johnnycode) 的视频教程，提供代码解析和解释。若觉得代码和教程有用，请支持我的工作：

[![Buy Me A Coffee](https://cdn.buymeacoffee.com/buttons/default-blue.png)](https://www.buymeacoffee.com/johnnycode)

<br />

# 训练Atari游戏 <!-- omit from toc -->
若想快速开始训练AI玩Atari游戏，本教程无需编码和强化学习经验！我们使用RL Baselines3 Zoo框架，通过命令行即可轻松训练和测试AI模型。

[![视频封面](https://img.youtube.com/vi/aQsaH7Tzvp0/0.jpg)](https://youtu.be/aQsaH7Tzvp0)

<br />

若想学习强化学习：
- [安装指南](#安装指南)
- [入门强化学习教程](#入门强化学习教程)
    - [1. Gymnasium FrozenLake-v1（8x8格子）的Q-Learning](#1-gymnasium-frozenlake-v1-8x8格子的q-learning)
      - [观看Q-Learning在FrozenLake-v1训练时的值变化](#观看q-learning在frozenlake-v1训练时的值变化)
    - [2. Gymnasium Taxi-v3（多目标）的Q-Learning](#2-gymnasium-taxi-v3多目标的q-learning)
    - [3. Gymnasium MountainCar-v0（连续状态空间）的Q-Learning](#3-gymnasium-mountaincar-v0连续状态空间的q-learning)
    - [4. Gymnasium CartPole-v1（多维连续状态空间）的Q-Learning](#4-gymnasium-cartpole-v1多维连续状态空间的q-learning)
    - [5. Gymnasium Acrobot-v1（高维Q表）的Q-Learning](#5-gymnasium-acrobot-v1高维q表的q-learning)
    - [6. Gymnasium Pendulum-v1（连续状态和动作空间）的Q-Learning](#6-gymnasium-pendulum-v1连续状态和动作空间的q-learning)
    - [7. Gymnasium MountainCarContinuous-v0（陷入局部最优）的Q-Learning](#7-gymnasium-mountaincarcontinuous-v0陷入局部最优的q-learning)
- [深度强化学习教程](#深度强化学习教程)
    - [神经网络入门](#神经网络入门)
    - [深度Q-Learning（DQN）原理与实现](#深度q-learning-aka-deep-q-network-dqn-原理与实现)
      - [使用PyTorch实现DQN并训练Flappy Bird](#使用pytorch实现dqn并训练flappy-bird)
    - [将DQN应用于Gymnasium Mountain Car](#将dqn应用于gymnasium-mountain-car)
    - [卷积神经网络（CNN）入门](#卷积神经网络-cnn-入门)
- [Stable Baselines3教程](#stable-baselines3教程)
    - [Stable Baselines3入门：训练Gymnasium MuJoCo Humanoid-v4](#stable-baselines3入门训练gymnasium-mujoco-humanoid-v4)
    - [Stable Baselines3算法选择指南](#stable-baselines3算法选择指南)
    - [动态加载算法训练Gymnasium Pendulum](#动态加载算法训练gymnasium-pendulum-v1)
    - [训练时自动停止条件设置](#训练时自动停止条件设置)

<br />

# 安装指南
Gymnasium官方支持Linux和Mac OS，但Windows存在兼容性问题。对于Box2D环境（如Bipedal Walker、Car Racing、Lunar Lander），Windows用户可能遇到：
* ERROR: Failed building wheels for box2d-py
* ERROR: Command swig.exe failed
* ERROR: 需要Microsoft Visual C++ 14.0或更高版本。

我的Windows安装指南可解决这些问题：

[![安装指南](https://img.youtube.com/vi/gMgj4pSHLww/0.jpg)](https://youtu.be/gMgj4pSHLww)

若上述方法仍失败，可使用Windows Subsystem for Linux (WSL) 安装Box2D环境：

[![WSL安装指南](https://img.youtube.com/vi/yxS5WErjYxc/0.jpg)](https://youtu.be/yxS5WErjYxc)

<br />

# 入门强化学习教程

### 1. Gymnasium FrozenLake-v1（8x8格子）的Q-Learning
适合新手的起点。本教程逐步讲解用Q-Learning解决FrozenLake-v1（8x8地图）。环境简单，便于理解Q-Learning机制。使用ε-贪心算法平衡探索与利用。代码侧重实践，不深入理论。

[![教程视频](https://img.youtube.com/vi/ZhoIgo3qqLU/0.jpg)](https://youtu.be/ZhoIgo3qqLU)

##### 代码参考：
* [frozen_lake_q.py](https://github.com/johnnycode8/gym_solutions/blob/main/frozen_lake_q.py)

#### 观看Q-Learning在FrozenLake-v1训练时的值变化
此增强版环境实时显示Q值，帮助理解学习过程。地图放大以便清晰观察Q值变化，并提供速度调节快捷键：

[![实时Q值演示](https://img.youtube.com/vi/1W_LOB-0IEY/0.jpg)](https://youtu.be/1W_LOB-0IEY)

##### 代码参考：
* [frozen_lake_enhanced.py](https://github.com/johnnycode8/gym_solutions/blob/main/frozen_lake_enhanced.py)（增强版环境）
* [frozen_lake_qe.py](https://github.com/johnnycode8/gym_solutions/blob/main/frozen_lake_qe.py)（使用增强版环境的Q-Learning代码）

<br />

### 2. Gymnasium Taxi-v3（多目标）的Q-Learning
Taxi-v3环境要求智能体（出租车）接载乘客并送达目的地。与FrozenLake不同，其状态空间更复杂：

[![教程视频](https://img.youtube.com/vi/9fAnzZ6xzhA/0.jpg)](https://youtu.be/9fAnzZ6xzhA)

##### 代码参考：
* [taxi_q.py](https://github.com/johnnycode8/gym_solutions/blob/main/taxi_q.py)

<br />

### 3. Gymnasium MountainCar-v0（连续状态空间）的Q-Learning
本教程用Q-Learning解决MountainCar-v0。与离散状态的FrozenLake不同，其状态空间是连续的（汽车在连续地形上移动）：

[![教程视频](https://img.youtube.com/vi/_SWnNhM5w-g/0.jpg)](https://youtu.be/_SWnNhM5w-g)

##### 代码参考：
* [mountain_car_q.py](https://github.com/johnnycode8/gym_solutions/blob/main/mountain_car_q.py)

<br />

### 4. Gymnasium CartPole-v1（多维连续状态空间）的Q-Learning
CartPole-v1的Q-Learning教程。其状态空间包含小车位置/速度和杆的角度/角速度：

[![教程视频](https://img.youtube.com/vi/2u1REHeHMrg/0.jpg)](https://youtu.be/2u1REHeHMrg)

##### 代码参考：
* [cartpole_q.py](https://github.com/johnnycode8/gym_solutions/blob/main/cartpole_q.py)

<br />

### 5. Gymnasium Acrobot-v1（高维Q表）的Q-Learning
使用7维Q表解决Acrobot-v1环境：

[![教程视频](https://img.youtube.com/vi/Pf1lEv3b5s4/0.jpg)](https://youtu.be/Pf1lEv3b5s4)

##### 代码参考：
* [acrobot_q.py](https://github.com/johnnycode8/gym_solutions/blob/main/acrobot_q.py)

<br />

### 6. Gymnasium Pendulum-v1（连续状态和动作空间）的Q-Learning
Q-Learning解决Pendulum-v1（连续状态和动作空间）：

[![教程视频](https://img.youtube.com/vi/o2NMWV5sImM/0.jpg)](https://youtu.be/o2NMWV5sImM)

##### 代码参考：
* [pendulum_q.py](https://github.com/johnnycode8/gym_solutions/blob/main/pendulum_q.py)

<br />

### 7. Gymnasium MountainCarContinuous-v0（陷入局部最优）的Q-Learning
Q-Learning解决MountainCarContinuous-v0（易陷入局部最优）：

[![教程视频](https://img.youtube.com/vi/1Ms2UqRC8LA/0.jpg)](https://youtu.be/1Ms2UqRC8LA)

##### 代码参考：
* [mountain_car_cont_q.py](https://github.com/johnnycode8/gym_solutions/blob/main/mountain_car_cont_q.py)

<br /><br />

# 深度强化学习教程

### 神经网络入门
通过最小神经网络示例学习Loss计算和梯度下降：

[![神经网络教程](https://img.youtube.com/vi/6kOvmZDEMdc/0.jpg)](https://youtu.be/6kOvmZDEMdc)

##### 代码参考：
* [Basic Neural Network](https://github.com/johnnycode8/basic_neural_network)

<br />

### 深度Q-Learning（DQN）原理与实现
通过FrozenLake-v1讲解DQN原理，使用PyTorch实现策略网络和目标网络，结合经验回放：

[![DQN教程](https://img.youtube.com/vi/EUrWGTCGzlA/0.jpg)](https://youtu.be/EUrWGTCGzlA)

##### 代码参考：
* [frozen_lake_dql.py](https://github.com/johnnycode8/gym_solutions/blob/main/frozen_lake_dql.py)

##### 依赖：
* [PyTorch](https://pytorch.org/)

#### 使用PyTorch实现DQN并训练Flappy Bird
深入理解DQN实现：[DQN PyTorch教程](https://github.com/johnnycode8/dqn_pytorch)

<br />

### 将DQN应用于Gymnasium Mountain Car
使用DQN重新解决MountainCar-v0，对比Q-Learning实现：

[![教程视频](https://img.youtube.com/vi/oceguqZxjn4/0.jpg)](https://youtu.be/oceguqZxjn4)

##### 代码参考：
* [mountain_car_dql.py](https://github.com/johnnycode8/gym_solutions/blob/main/mountain_car_dql.py)

##### 依赖：
* [PyTorch](https://pytorch.org/)

<br />

### 卷积神经网络（CNN）入门
通过FrozenLake-v1演示CNN在DQN中的应用，处理图像输入：

[![CNN教程](https://img.youtube.com/vi/qKePPepISiA/0.jpg)](https://youtu.be/qKePPepISiA)

##### 代码参考：
* [frozen_lake_dql_cnn.py](https://github.com/johnnycode8/gym_solutions/blob/main/frozen_lake_dql_cnn.py)

##### 依赖：
* [PyTorch](https://pytorch.org/)

<br /><br />

# Stable Baselines3教程

### Stable Baselines3入门：训练Gymnasium MuJoCo Humanoid-v4
使用SAC算法训练Humanoid-v4，结合TensorBoard监控训练：

[![教程视频](https://img.youtube.com/vi/OqvXHi_QtT0/0.jpg)](https://youtu.be/OqvXHi_QtT0)

##### 代码参考：
* [sb3.py](https://github.com/johnnycode8/gym_solutions/blob/main/sb3.py)

##### 依赖：
* [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/)

<br />

### Stable Baselines3算法选择指南
帮助新手选择适合的强化学习算法：

[![算法选择教程](https://img.youtube.com/vi/2AFl-iWGQzc/0.jpg)](https://youtu.be/2AFl-iWGQzc)

<br />

### 动态加载算法训练Gymnasium Pendulum-v1
通过Pendulum-v1演示动态加载SAC和TD3算法：

[![教程视频](https://img.youtube.com/vi/nf2IE2GEJ-s/0.jpg)](https://youtu.be/nf2IE2GEJ-s)

##### 代码参考：
* [sb3v2.py](https://github.com/johnnycode8/gym_solutions/blob/main/sb3v2.py)

<br />

### 训练时自动停止条件设置
通过BipedalWalker-v3演示训练终止条件：

[![教程视频](https://img.youtube.com/vi/mCkgLweyMqo/0.jpg)](https://youtu.be/mCkgLweyMqo)

##### 代码参考：
* [sb3v3.py](https://github.com/johnnycode8/gym_solutions/blob/main/sb3v3.py)

<p align="right">(<a href="#readme-top">返回顶部</a>)</p>